{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 09:36:23.659283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 09:36:23.804858: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-02 09:36:24.263286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: “/usr/local/cuda-12.0/lib64:/usr/local/lib/:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib”\n",
      "2024-04-02 09:36:24.263352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: “/usr/local/cuda-12.0/lib64:/usr/local/lib/:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/x86_64-linux-gnu:/opt/ros/humble/lib”\n",
      "2024-04-02 09:36:24.263356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from waymo_open_dataset.protos import scenario_pb2\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from waymo_open_dataset.utils import frame_utils, transform_utils, range_image_utils\n",
    "from waymo_types import object_type, lane_type, road_line_type, road_edge_type, signal_state, polyline_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1863454917318776530_1040_000_1060_000\n",
      "1553699522542368\n",
      "7\n",
      "3trIuzYfB0l7yFpIOu2VLA\n",
      "CcI9b1iec73z1XiyOy1wWw\n",
      "HtFZpEpsYcSBBcSw2RJXSw\n",
      "LcK7v6ctnkiRwl2bYn7S-g\n",
      "_SCULkFvfd3JgxGYChOJhQ\n",
      "iFXEyf6yuNggNBzdm7EGog\n",
      "yOWyEitzhXI_S_B1xArLQA\n",
      "2605548f-9837-42d5-a6d0-fc91b678dc4c\n",
      "445010b0-0a59-4563-892d-215b88b74af1\n",
      "735562aa-fbaa-454c-8bf2-e650a43bc56e\n",
      "b1d1c9ce-68d7-453f-ba34-bfc9b94ba68a\n",
      "fb064966-279c-4dd3-ba25-7b9c462871ee\n",
      "22368d6e-4859-47e5-8bfe-80aceac9b5cf\n",
      "3abcdc90-6da0-4c6e-8521-3ee497ee5755\n",
      "4f0608e1-32ca-49d6-b344-d4b0b3f19546\n",
      "3trIuzYfB0l7yFpIOu2VLA_FRONT\n",
      "CcI9b1iec73z1XiyOy1wWw_FRONT\n",
      "_SCULkFvfd3JgxGYChOJhQ_FRONT\n",
      "3trIuzYfB0l7yFpIOu2VLA_FRONT_RIGHT\n",
      "yOWyEitzhXI_S_B1xArLQA_FRONT_RIGHT\n",
      "yOWyEitzhXI_S_B1xArLQA_SIDE_RIGHT\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "path_to_wod = '/home/erik/big1/waymo_perception/individual_files/training'\n",
    "segment_name = 'segment-1863454917318776530_1040_000_1060_000_with_camera_labels.tfrecord'\n",
    "\n",
    "data_file = os.path.join(path_to_wod, segment_name)\n",
    "dataset = tf.data.TFRecordDataset(data_file, compression_type='')\n",
    "\n",
    "i=0\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    print(frame.context.name)\n",
    "    print(frame.timestamp_micros)\n",
    "    #print(len(frame.images))\n",
    "    print(len(frame.laser_labels))\n",
    "    for label in frame.laser_labels:\n",
    "        print(str(label.id))\n",
    "    for label in frame.camera_labels:\n",
    "        for single_label in label.labels:\n",
    "            print(single_label.id)\n",
    "        #if label.labels.association in [laser_label.id for laser_label in frame.laser_labels]:\n",
    "        #    print('Present')\n",
    "    for label in frame.projected_lidar_labels:\n",
    "        for label in label.labels:\n",
    "            print(label.id)\n",
    "    print(len(frame.camera_labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo_dataset_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
